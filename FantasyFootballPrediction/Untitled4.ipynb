{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Roman Lutz. All rights reserved.\n",
    "# The use and distribution terms for this software are covered by the\n",
    "# Eclipse Public License 1.0 (http://opensource.org/licenses/eclipse-1.0.php)\n",
    "# which can be found in the file LICENSE.md at the root of this distribution.\n",
    "# By using this software in any fashion, you are agreeing to be bound by\n",
    "# the terms of this license.\n",
    "# You must not remove this notice, or any other, from this software.\n",
    "\n",
    "import pdb\n",
    "import numpy as np\n",
    "from sklearn.svm import SVR\n",
    "from sklearn import preprocessing\n",
    "from sklearn import cross_validation\n",
    "from sklearn import feature_selection\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from create_datasets import test_players\n",
    "import time\n",
    "from metrics import mean_relative_error\n",
    "from plots import histogram\n",
    "import sklearn.model_selection\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import sklearn\n",
    "import threading\n",
    "\n",
    "\n",
    "\"\"\"Values for the SVR\"\"\"\n",
    "kernels = ['rbf', 'linear', 'sigmoid']\n",
    "degrees = [2]\n",
    "gamma_values = [0.05*k for k in range(1,4)]\n",
    "C_values = [0.25*k for k in range(1, 5)]\n",
    "epsilon_values = [0.05*k for k in range(1, 6)]\n",
    "\n",
    "\n",
    "overall_best_params = []\n",
    "def hyperparameter(x, y):\n",
    "    \"\"\" \n",
    "    Get the best hyperparameters from cross validation of the training data\n",
    "    Then use the best hyperparameters from (linear, rbf, sigmoid, poly) to evaluate performance on the testing data \n",
    "    Full Parameters:parameters = {'kernel':('linear', 'rbf', 'sigmoid'), 'degree':(degrees), 'C':(C_values), 'gamma':(gamma_values), 'epsilon':(epsilon_values)}\n",
    "    \"\"\"\n",
    "    # elements of this list are dictionaries that contain the best parameters for each kernel to use on test data (2017 data)\n",
    "    # Since we are predicting scores and using regression, use SVR()\n",
    "\n",
    "    svr = sklearn.svm.SVR()\n",
    " \n",
    "\n",
    "    # linear \n",
    "    \"\"\"\n",
    "    linear_kernel = ['linear']\n",
    "    linear_parameters = {'kernel':(linear_kernel), 'C':(C_values), 'gamma':(gamma_values), 'epsilon':(epsilon_values)}\n",
    "    clf = sklearn.model_selection.GridSearchCV(svr, linear_parameters, verbose=5, scoring='neg_mean_absolute_error')\n",
    "    clf.fit(x, y)\n",
    "    cvres = clf.cv_results_\n",
    "    print(\"LINEAR:\")\n",
    "    for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "        print(mean_score, params)\n",
    "    print(\"Best: \" + str(clf.best_params_))\n",
    "    best_linear_param = clf.best_params_\n",
    "    print(type(clf.best_params_))\n",
    "    overall_best_params.add(clf.best_params_)\n",
    "    pdb.set_trace()\n",
    "\n",
    "    # rbf\n",
    "    rbf_kernel = ['rbf']\n",
    "    rbf_parameters = {'kernel':(rbf_kernel), 'C':(C_values), 'gamma':(gamma_values), 'epsilon':(epsilon_values)}\n",
    "    clf = sklearn.model_selection.GridSearchCV(svr, rbf_parameters, verbose=5, scoring='neg_mean_absolute_error')\n",
    "    clf.fit(x, y)\n",
    "    cvres = clf.cv_results_\n",
    "    print(\"RBF:\")\n",
    "    for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "        print(mean_score, params)\n",
    "    print(\"Best: \" + str(clf.best_params_))\n",
    "    overall_best_params.add(clf.best_params_)\n",
    "    pdb.set_trace()\n",
    "\n",
    "    # sigmoid\n",
    "    sigmoid_kernel = ['sigmoid']\n",
    "    sigmoid_parameters = {'kernel':(sigmoid_kernel), 'C':(C_values), 'gamma':(gamma_values), 'epsilon':(epsilon_values)}\n",
    "    clf = sklearn.model_selection.GridSearchCV(svr, sigmoid_parameters, verbose=5, scoring='neg_mean_absolute_error')\n",
    "    clf.fit(x, y)\n",
    "    cvres = clf.cv_results_\n",
    "    print(\"SIGMOID:\")\n",
    "    for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "        print(mean_score, params)\n",
    "    print(\"Best: \" + str(clf.best_params_))\n",
    "    overall_best_params.add(clf.best_params_)\n",
    "    pdb.set_trace()\n",
    "    \"\"\"\n",
    "    # poly\n",
    "    poly_kernel = ['poly']\n",
    "    poly_parameters = {'kernel':(poly_kernel), 'degree':(degrees)}\n",
    "    clf = sklearn.model_selection.GridSearchCV(svr, poly_parameters, verbose=5, scoring='neg_mean_absolute_error')\n",
    "    clf.fit(x, y)\n",
    "    cvres = clf.cv_results_\n",
    "    print(\"POLYNOMIAL:\")\n",
    "    for mean_score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "        print(mean_score, params)\n",
    "    print(\"Best: \" + str(clf.best_params_))\n",
    "    overall_best_params.add(clf.best_params_)\n",
    "    pdb.set_trace()\n",
    "    \n",
    "    \n",
    "   \n",
    "\n",
    "\n",
    "# Only one of the feature selection methods can be chosen\n",
    "FEATURE_SELECTION = False\n",
    "MANUAL_FEATURE_SELECTION = False\n",
    "FEATURE_NORMALIZATION = False\n",
    "HYPERPARAMETER_SELECTION = True\n",
    "HISTOGRAM = True\n",
    "\n",
    "\n",
    "train = np.load('train.npy')\n",
    "test = np.load('test.npy')\n",
    "\n",
    "\"\"\"\n",
    "# load data\n",
    "# indices are\n",
    "# 0: QB id\n",
    "# 1: QB name\n",
    "# 2: QB age\n",
    "# 3: QB years pro\n",
    "# 4\n",
    "# 5-16: last game QB stats\n",
    "# 17-28: last 10 games QB stats\n",
    "# 29-32: last game defense stats\n",
    "# 33-36: last 10 games defense stats\n",
    "# 37: actual fantasy score = target\n",
    "\"\"\"\n",
    "train_x = train[:, 2:37].astype(np.float)\n",
    "train_y = train[:, 37].astype(np.float)\n",
    "test_x = test[:, 2:37].astype(np.float)\n",
    "test_y = test[:, 37].astype(np.float)\n",
    "\n",
    "\n",
    "# Feature Normalization\n",
    "if FEATURE_NORMALIZATION:\n",
    "    print 'started feature normalization', time.time()\n",
    "    x = np.concatenate((train_x, test_x), axis=0)\n",
    "    x = preprocessing.scale(x)\n",
    "    train_x = x[:len(train_x)]\n",
    "    test_x = x[len(train_x):]\n",
    "\n",
    "\n",
    "# Recursive Feature Elimination with cross-validation (RFECV)\n",
    "if FEATURE_SELECTION:\n",
    "    print 'started feature selection', time.time()\n",
    "    selector = feature_selection.RFECV(estimator=SVR(kernel='linear'), step=3, cv=5)\n",
    "    selector.fit(train_x, train_y)\n",
    "    train_x = selector.transform(train_x)\n",
    "    test_x = selector.transform(test_x)\n",
    "    print selector.ranking_\n",
    "elif MANUAL_FEATURE_SELECTION: # leave out the two point attempts\n",
    "    manual_indices = [0, 1, 2, 3, 4, 5, 8, 9, 10, 13, 14, 15, 16, 17, 20, 21, 22, 25, 26, 27, 28, 29, 30, 31, 32, 33]\n",
    "    train_x = train_x[:, manual_indices]\n",
    "    test_x = test_x[:, manual_indices]\n",
    "\n",
    "\n",
    "# Hyperparameter Selection\n",
    "if HYPERPARAMETER_SELECTION:\n",
    "    hyperparameter(train_x, train_y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
